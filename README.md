# ğŸ–ï¸ Hand Gesture Recognition: MLP vs CNN

A comparative study between **Multilayer Perceptron (MLP)** using hand landmarks and a **Convolutional Neural Network (CNN)** using raw gesture images for hand gesture classification.

---

## ğŸ“Œ Overview

This project aims to evaluate two different approaches for recognizing static hand gestures:

1. **MLP with MediaPipe Landmarks** â€“ Uses 3D hand landmarks extracted via [MediaPipe](https://google.github.io/mediapipe/solutions/hands).
2. **CNN on Raw Images** â€“ Trains a deep convolutional network on raw gesture images.

---

## ğŸ§  Models & Techniques

### 1. ğŸ”· MLP (Using MediaPipe Landmarks)
- **Input:** 21 hand landmarks (x, y, z) â†’ 63 features
- **Framework:** scikit-learn / TensorFlow (dense layers)
- **Advantages:** Lightweight, fast, and interpretable
- **Dependencies:** Accurate landmark extraction via MediaPipe

### 2. ğŸ”¶ CNN (Using Raw Images)
- **Input:** Preprocessed hand gesture images
- **Architecture:** 3 Conv layers â†’ MaxPooling â†’ Flatten â†’ Dense layers
- **Advantages:** Learns spatial features directly from pixels
- **Challenges:** Requires larger datasets and compute resources

---

## ğŸ“ Project Structure

ğŸ“¦ Hand-Gesture-Recognition â”œâ”€â”€ cnn_image_model/ # CNN-based pipeline â”‚ â”œâ”€â”€ preprocess_images.py â”‚ â”œâ”€â”€ train_cnn.py â”œâ”€â”€ mediapipe_landmark_model/ # MLP-based pipeline â”‚ â”œâ”€â”€ extract_landmarks.py â”‚ â”œâ”€â”€ train_mlp.py â”œâ”€â”€ dataset/ â”‚ â”œâ”€â”€ images/ â”‚ â”œâ”€â”€ landmarks.csv â”œâ”€â”€ results/ â”‚ â”œâ”€â”€ mlp_accuracy.png â”‚ â”œâ”€â”€ cnn_accuracy.png â”œâ”€â”€ requirements.txt â””â”€â”€ README.md

yaml
Copy
Edit

---

## ğŸ“Š Results

| Model | Accuracy | Precision | Recall | F1 Score |
|-------|----------|-----------|--------|----------|
| **MLP** | 92% | 91% | 92% | 91% |
| **CNN** | 96% | 95% | 96% | 95% |

âœ… **CNN outperforms MLP**, but MLP still provides strong results with faster training and less compute.

---

## ğŸš€ Getting Started

### Clone the repo
```bash
git clone https://github.com/yourusername/hand-gesture-mlp-vs-cnn.git
cd hand-gesture-mlp-vs-cnn
Install dependencies
bash
Copy
Edit
pip install -r requirements.txt
â–¶ï¸ How to Run
Train MLP model (using landmarks)
bash
Copy
Edit
cd mediapipe_landmark_model
python train_mlp.py
Train CNN model (using images)
bash
Copy
Edit
cd cnn_image_model
python train_cnn.py
ğŸ“‚ Dataset
You can use:

Your own webcam-captured dataset

Public datasets like:

Rock-Paper-Scissors (Kaggle)

Hand Gesture Recognition Database (UCI)

ğŸ“Œ Future Improvements
âºï¸ Real-time gesture prediction

ğŸ§  LSTM for dynamic gesture sequences

ğŸ” Data augmentation for robustness

ğŸ¤ Integrate with sign language recognition systems

ğŸ‘¨â€ğŸ’» Author
Salah Hossam
Machine Learning & Embedded Systems Engineer
